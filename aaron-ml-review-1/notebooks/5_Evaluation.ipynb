{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive & Import Libraries"
      ],
      "metadata": {
        "id": "o2REDl5HKFEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import pprint\n",
        "from google.colab import drive\n",
        "from collections import defaultdict\n",
        "import re  # We need regex for the HMM oracle\n",
        "\n",
        "# --- Mount Drive ---\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Configuration ---\n",
        "BASE_PATH = '/content/drive/My Drive/ml-hackathon'\n",
        "DATA_PATH = os.path.join(BASE_PATH, 'data')\n",
        "MODEL_PATH = os.path.join(BASE_PATH, 'models')\n",
        "\n",
        "# --- Input Files ---\n",
        "# We need ALL our files for the final run\n",
        "CORPUS_JSON_PATH = os.path.join(DATA_PATH, 'corpus_by_length.json')\n",
        "TEST_JSON_PATH = os.path.join(DATA_PATH, 'test_by_length.json')\n",
        "HMM_MODEL_PATH = os.path.join(MODEL_PATH, 'hmm_probabilities.json')\n",
        "Q_TABLE_PATH = os.path.join(MODEL_PATH, 'q_table.json')\n",
        "\n",
        "print(\"--- Evaluation Notebook ---\")\n",
        "print(f\"Base path set to: {BASE_PATH}\")\n",
        "print(\"Loading all data and trained models...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKJL3ES8KJk8",
        "outputId": "a9218ecd-8cdd-4710-d2c5-7070190394b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "--- Evaluation Notebook ---\n",
            "Base path set to: /content/drive/My Drive/ml-hackathon\n",
            "Loading all data and trained models...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load All Data & Models"
      ],
      "metadata": {
        "id": "tTKNJYl1Kgiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_file(file_path):\n",
        "    \"\"\"Loads a JSON file from the given path.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"Successfully loaded: {file_path}\")\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: File not found at {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred loading {file_path}: {e}\")\n",
        "    return None\n",
        "\n",
        "# --- Load All Data ---\n",
        "corpus_by_length = load_json_file(CORPUS_JSON_PATH)\n",
        "test_by_length = load_json_file(TEST_JSON_PATH)\n",
        "hmm_models = load_json_file(HMM_MODEL_PATH)\n",
        "q_table = load_json_file(Q_TABLE_PATH) # <-- Loading our trained brain\n",
        "\n",
        "# --- Data Correction ---\n",
        "if corpus_by_length:\n",
        "    corpus_by_length = {int(k): v for k, v in corpus_by_length.items()}\n",
        "if test_by_length:\n",
        "    test_by_length = {int(k): v for k, v in test_by_length.items()}\n",
        "if hmm_models:\n",
        "    hmm_models = {int(k): v for k, v in hmm_models.items()}\n",
        "\n",
        "if corpus_by_length and test_by_length and hmm_models and q_table:\n",
        "    print(\"\\nAll data and models loaded successfully.\")\n",
        "else:\n",
        "    print(\"\\nError: Failed to load one or more essential files.\")\n",
        "\n",
        "# --- Constants ---\n",
        "ALPHABET = list(string.ascii_uppercase)\n",
        "LIVES_ALLOWED = 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk8meHB2KiU5",
        "outputId": "573e05e6-c14c-4f53-9c5c-9461b1f28817"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded: /content/drive/My Drive/ml-hackathon/data/corpus_by_length.json\n",
            "Successfully loaded: /content/drive/My Drive/ml-hackathon/data/test_by_length.json\n",
            "Successfully loaded: /content/drive/My Drive/ml-hackathon/models/hmm_probabilities.json\n",
            "Successfully loaded: /content/drive/My Drive/ml-hackathon/models/q_table.json\n",
            "\n",
            "All data and models loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-define the Hangman Environment"
      ],
      "metadata": {
        "id": "u_4Vv0-JKvve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HangmanEnvironment:\n",
        "    \"\"\"\n",
        "    This class implements the Hangman game environment.\n",
        "    We add a 'set_word' method for evaluation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, word_list, lives=6):\n",
        "        # word_list is not needed if we set the word manually\n",
        "        self.word_list = word_list\n",
        "        self.total_lives = lives\n",
        "        self.secret_word = \"\"\n",
        "        self.masked_word = []\n",
        "        self.lives_left = 0\n",
        "        self.guessed_letters = set()\n",
        "        self.game_over = True\n",
        "        self.word_length = 0\n",
        "\n",
        "    def reset_with_word(self, secret_word):\n",
        "        \"\"\"\n",
        "        Starts a new game with a SPECIFIC word for evaluation.\n",
        "        \"\"\"\n",
        "        self.secret_word = secret_word.upper()\n",
        "        self.word_length = len(self.secret_word)\n",
        "        self.masked_word = [\"_\"] * self.word_length\n",
        "        self.lives_left = self.total_lives\n",
        "        self.guessed_letters = set()\n",
        "        self.game_over = False\n",
        "        return self._get_current_state()\n",
        "\n",
        "    def _get_current_state(self):\n",
        "        \"\"\"Returns the current state.\"\"\"\n",
        "        return {\n",
        "            \"masked_word\": \"\".join(self.masked_word),\n",
        "            \"word_length\": self.word_length,\n",
        "            \"lives_left\": self.lives_left,\n",
        "            \"guessed_letters\": sorted(list(self.guessed_letters)),\n",
        "            \"game_over\": self.game_over\n",
        "        }\n",
        "\n",
        "    def step(self, action_letter):\n",
        "        \"\"\"Guesses a letter and returns the new state, reward, and game_over status.\"\"\"\n",
        "        if self.game_over:\n",
        "            return self._get_current_state(), 0, True, {\"error\": \"Game is already over.\"}\n",
        "\n",
        "        action_letter = action_letter.upper()\n",
        "\n",
        "        info = {\"guess_type\": \"\"}\n",
        "        is_win = False\n",
        "        is_loss = False\n",
        "\n",
        "        # Case 1: Repeated guess\n",
        "        if action_letter in self.guessed_letters:\n",
        "            info[\"guess_type\"] = \"repeated\"\n",
        "\n",
        "        # Case 2: Wrong guess\n",
        "        elif action_letter not in self.secret_word:\n",
        "            self.lives_left -= 1\n",
        "            self.guessed_letters.add(action_letter)\n",
        "            info[\"guess_type\"] = \"wrong\"\n",
        "\n",
        "        # Case 3: Correct guess\n",
        "        else:\n",
        "            self.guessed_letters.add(action_letter)\n",
        "            info[\"guess_type\"] = \"correct\"\n",
        "            new_masked_word = list(self.masked_word)\n",
        "            for i, char in enumerate(self.secret_word):\n",
        "                if char == action_letter:\n",
        "                    new_masked_word[i] = action_letter\n",
        "            self.masked_word = new_masked_word\n",
        "\n",
        "        # --- Check for Game Over ---\n",
        "        if \"_\" not in self.masked_word:\n",
        "            self.game_over = True\n",
        "            is_win = True\n",
        "        elif self.lives_left <= 0:\n",
        "            self.game_over = True\n",
        "            is_loss = True\n",
        "\n",
        "        # During evaluation, we don't need rewards, just info\n",
        "        return self._get_current_state(), 0, self.game_over, info"
      ],
      "metadata": {
        "id": "pRgbW-txKxcH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-define the \"HMM Oracle\""
      ],
      "metadata": {
        "id": "YkZZxmQOLLf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def get_letter_probabilities(state, word_length):\n",
        "    \"\"\"\n",
        "    This is our \"HMM Oracle.\"\n",
        "    It calculates the probability of each un-guessed letter.\n",
        "    It returns a list of (letter, probability) tuples.\n",
        "    \"\"\"\n",
        "\n",
        "    masked_word = state[\"masked_word\"]\n",
        "    guessed_letters = set(state[\"guessed_letters\"])\n",
        "\n",
        "    model = hmm_models[word_length]\n",
        "    word_list = corpus_by_length[word_length]\n",
        "\n",
        "    pattern = \"\"\n",
        "    for char in masked_word:\n",
        "        if char == \"_\":\n",
        "            pattern += f\"[^{''.join(guessed_letters)}]\"\n",
        "        else:\n",
        "            pattern += char\n",
        "\n",
        "    try:\n",
        "        regex = re.compile(f\"^{pattern}$\")\n",
        "        candidate_words = [word for word in word_list if regex.match(word)]\n",
        "    except:\n",
        "        candidate_words = []\n",
        "\n",
        "    letter_probs = defaultdict(float)\n",
        "\n",
        "    if not candidate_words:\n",
        "        prob_model = model['unigram']\n",
        "        for char in ALPHABET:\n",
        "            if char not in guessed_letters:\n",
        "                letter_probs[char] = prob_model.get(char, 1e-6)\n",
        "    else:\n",
        "        blank_indices = [i for i, char in enumerate(masked_word) if char == \"_\"]\n",
        "        total_blank_letters = 0\n",
        "\n",
        "        for word in candidate_words:\n",
        "            for i in blank_indices:\n",
        "                letter_at_blank = word[i]\n",
        "                if letter_at_blank not in guessed_letters:\n",
        "                    letter_probs[letter_at_blank] += 1\n",
        "                    total_blank_letters += 1\n",
        "\n",
        "        if total_blank_letters > 0:\n",
        "            for char in letter_probs:\n",
        "                letter_probs[char] /= total_blank_letters\n",
        "\n",
        "        if not letter_probs:\n",
        "            prob_model = model['unigram']\n",
        "            for char in ALPHABET:\n",
        "                if char not in guessed_letters:\n",
        "                    letter_probs[char] = prob_model.get(char, 1e-6)\n",
        "\n",
        "    sorted_probs = sorted(letter_probs.items(), key=lambda item: item[1], reverse=True)\n",
        "    return sorted_probs"
      ],
      "metadata": {
        "id": "TTcVkQAjLNAA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Re-define the Q-Learning Agent (for Evaluation)"
      ],
      "metadata": {
        "id": "qfBjbGXXLTsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    \"\"\"\n",
        "    This is the RL agent \"brain\" for EVALUATION.\n",
        "    Epsilon is 0. Uses the new, smarter state.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, q_table):\n",
        "        self.actions = [0, 1, 2]\n",
        "        self.q_table = q_table\n",
        "        print(\"Agent loaded with pre-trained Q-table. Ready for evaluation.\")\n",
        "\n",
        "    def _get_state_key(self, state, hmm_prob_info):\n",
        "        \"\"\"\n",
        "        This is our STATE ABSTRACTION function.\n",
        "        \"\"\"\n",
        "        lives = state[\"lives_left\"]\n",
        "        unique_letters_in_mask = len(set(c for c in state[\"masked_word\"] if c != '_'))\n",
        "\n",
        "        if not hmm_prob_info:\n",
        "            best_prob = 0.0\n",
        "        else:\n",
        "            best_prob = hmm_prob_info[0][1]\n",
        "\n",
        "        prob_bin = int(best_prob * 10)\n",
        "\n",
        "        return f\"L:{lives}_U:{unique_letters_in_mask}_P:{prob_bin}\"\n",
        "\n",
        "    def choose_action(self, state, hmm_prob_info):\n",
        "        \"\"\"\n",
        "        Chooses the BEST action from the Q-table. No epsilon.\n",
        "        \"\"\"\n",
        "        state_key = self._get_state_key(state, hmm_prob_info)\n",
        "        q_values = self.q_table.get(state_key, {})\n",
        "\n",
        "        if not q_values:\n",
        "            return 0 # Default to best guess\n",
        "\n",
        "        # Q-table keys are \"0\", \"1\", \"2\". We cast to int.\n",
        "        return int(max(q_values, key=lambda k: q_values.get(k, 0.0)))"
      ],
      "metadata": {
        "id": "l-O9anjwLV5v"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Final Evaluation"
      ],
      "metadata": {
        "id": "4Cv7v3ZgLfQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Starting Final Evaluation ---\")\n",
        "print(f\"Loading test set and trained agent...\")\n",
        "\n",
        "all_test_words = [word for words in test_by_length.values() for word in words]\n",
        "num_test_games = len(all_test_words)\n",
        "\n",
        "eval_env = HangmanEnvironment(word_list=all_test_words, lives=LIVES_ALLOWED)\n",
        "agent = QLearningAgent(q_table=q_table)\n",
        "\n",
        "total_wins = 0\n",
        "total_wrong_guesses = 0\n",
        "total_repeated_guesses = 0\n",
        "\n",
        "print(f\"Running agent against {num_test_games} games from the test set...\")\n",
        "\n",
        "for i, word in enumerate(all_test_words):\n",
        "    if (i + 1) % 200 == 0:\n",
        "        print(f\"  ... playing game {i+1}/{num_test_games}\")\n",
        "\n",
        "    state = eval_env.reset_with_word(word)\n",
        "    word_length = state[\"word_length\"]\n",
        "    game_over = False\n",
        "\n",
        "    game_wrong_guesses = 0\n",
        "    game_repeated_guesses = 0\n",
        "\n",
        "    while not game_over:\n",
        "        # 1. Get HMM info\n",
        "        hmm_prob_info = get_letter_probabilities(state, word_length)\n",
        "\n",
        "        # 2. Agent chooses action\n",
        "        action = agent.choose_action(state, hmm_prob_info)\n",
        "\n",
        "        # 3. Translate action to letter\n",
        "        guess = None\n",
        "        suggested_letters = [letter for letter, prob in hmm_prob_info]\n",
        "\n",
        "        if action == 2 and len(suggested_letters) >= 3:\n",
        "            guess = suggested_letters[2]\n",
        "        elif (action == 1 or action == 2) and len(suggested_letters) >= 2:\n",
        "            guess = suggested_letters[1]\n",
        "        elif len(suggested_letters) >= 1:\n",
        "            guess = suggested_letters[0]\n",
        "        else:\n",
        "            # Failsafe: No valid letters from HMM\n",
        "            available_letters = [l for l in ALPHABET if l not in state[\"guessed_letters\"]]\n",
        "            if available_letters:\n",
        "                guess = random.choice(available_letters)\n",
        "            else:\n",
        "                break # Game is stuck\n",
        "\n",
        "        # 4. Take the step\n",
        "        next_state, _, game_over, info = eval_env.step(guess)\n",
        "\n",
        "        # 5. Record stats\n",
        "        if info[\"guess_type\"] == \"wrong\":\n",
        "            game_wrong_guesses += 1\n",
        "        elif info[\"guess_type\"] == \"repeated\":\n",
        "            game_repeated_guesses += 1\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # --- End of Game ---\n",
        "    if \"_\" not in state[\"masked_word\"]:\n",
        "        total_wins += 1\n",
        "\n",
        "    # --- DEFINITIVE ACCUMULATION LOGIC ---\n",
        "    total_wrong_guesses += game_wrong_guesses\n",
        "    total_repeated_guesses += game_repeated_guesses\n",
        "\n",
        "print(\"...Evaluation Complete.\")\n",
        "\n",
        "# --- Calculate Final Scores ---\n",
        "success_rate = total_wins / num_test_games\n",
        "\n",
        "score_from_wins = total_wins\n",
        "score_from_wrong = total_wrong_guesses * 5\n",
        "score_from_repeated = total_repeated_guesses * 2\n",
        "final_score = score_from_wins - score_from_wrong - score_from_repeated\n",
        "\n",
        "# --- Print Final Report ---\n",
        "print(\"\\n\\n--- FINAL EVALUATION RESULTS ---\")\n",
        "print(\"----------------------------------\")\n",
        "print(f\"Total Games Played: {num_test_games}\")\n",
        "print(f\"Total Wins:         {total_wins}\")\n",
        "print(f\"Success Rate:       {success_rate * 100:.2f}%\")\n",
        "print(f\"Avg. Wrong Guesses:   {total_wrong_guesses / num_test_games:.2f}\")\n",
        "print(f\"Avg. Repeated Guesses: {total_repeated_guesses / num_test_games:.2f}\")\n",
        "print(\"\\n--- SCORING BREAKDOWN ---\")\n",
        "print(f\"Score from Wins (+1 per win):      + {score_from_wins}\")\n",
        "print(f\"Penalty from Wrong (-5 per):     - {score_from_wrong}\")\n",
        "print(f\"Penalty from Repeated (-2 per):  - {score_from_repeated}\")\n",
        "print(\"----------------------------------\")\n",
        "print(f\"FINAL SCORE: {final_score}\")\n",
        "print(\"----------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o6ds0_qLhus",
        "outputId": "df475e53-b1e9-4755-b5c6-e242f1ed3820"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Final Evaluation ---\n",
            "Loading test set and trained agent...\n",
            "Agent loaded with pre-trained Q-table. Ready for evaluation.\n",
            "Running agent against 2000 games from the test set...\n",
            "  ... playing game 200/2000\n",
            "  ... playing game 400/2000\n",
            "  ... playing game 600/2000\n",
            "  ... playing game 800/2000\n",
            "  ... playing game 1000/2000\n",
            "  ... playing game 1200/2000\n",
            "  ... playing game 1400/2000\n",
            "  ... playing game 1600/2000\n",
            "  ... playing game 1800/2000\n",
            "  ... playing game 2000/2000\n",
            "...Evaluation Complete.\n",
            "\n",
            "\n",
            "--- FINAL EVALUATION RESULTS ---\n",
            "----------------------------------\n",
            "Total Games Played: 2000\n",
            "Total Wins:         326\n",
            "Success Rate:       16.30%\n",
            "Avg. Wrong Guesses:   5.67\n",
            "Avg. Repeated Guesses: 0.00\n",
            "\n",
            "--- SCORING BREAKDOWN ---\n",
            "Score from Wins (+1 per win):      + 326\n",
            "Penalty from Wrong (-5 per):     - 56730\n",
            "Penalty from Repeated (-2 per):  - 0\n",
            "----------------------------------\n",
            "FINAL SCORE: -56404\n",
            "----------------------------------\n"
          ]
        }
      ]
    }
  ]
}